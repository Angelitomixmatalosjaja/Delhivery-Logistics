{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Optimizing Logistics with Data: Delhivery Case Study\n",
    "Delhivery is one of India's leading logistics and supply chain companies. Known for its extensive reach and advanced delivery solutions, the company integrates cutting-edge technology to enable timely and reliable services across diverse regions.\n",
    "# üîç Project Objective\n",
    "This project focuses on analyzing logistics and delivery performance using Delhivery‚Äôs raw operational data. The goal is to extract meaningful insights that can improve logistics strategies, route optimization, and delivery efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_data = pd.read_csv('delhivery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144867 entries, 0 to 144866\n",
      "Data columns (total 24 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   data                            144867 non-null  object \n",
      " 1   trip_creation_time              144867 non-null  object \n",
      " 2   route_schedule_uuid             144867 non-null  object \n",
      " 3   route_type                      144867 non-null  object \n",
      " 4   trip_uuid                       144867 non-null  object \n",
      " 5   source_center                   144867 non-null  object \n",
      " 6   source_name                     144574 non-null  object \n",
      " 7   destination_center              144867 non-null  object \n",
      " 8   destination_name                144606 non-null  object \n",
      " 9   od_start_time                   144867 non-null  object \n",
      " 10  od_end_time                     144867 non-null  object \n",
      " 11  start_scan_to_end_scan          144867 non-null  float64\n",
      " 12  is_cutoff                       144867 non-null  bool   \n",
      " 13  cutoff_factor                   144867 non-null  int64  \n",
      " 14  cutoff_timestamp                144867 non-null  object \n",
      " 15  actual_distance_to_destination  144867 non-null  float64\n",
      " 16  actual_time                     144867 non-null  float64\n",
      " 17  osrm_time                       144867 non-null  float64\n",
      " 18  osrm_distance                   144867 non-null  float64\n",
      " 19  factor                          144867 non-null  float64\n",
      " 20  segment_actual_time             144867 non-null  float64\n",
      " 21  segment_osrm_time               144867 non-null  float64\n",
      " 22  segment_osrm_distance           144867 non-null  float64\n",
      " 23  segment_factor                  144867 non-null  float64\n",
      "dtypes: bool(1), float64(10), int64(1), object(12)\n",
      "memory usage: 25.6+ MB\n"
     ]
    }
   ],
   "source": [
    "delivery_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí° Potential Use Cases\n",
    "‚Ä¢ Trip Efficiency Analysis: Evaluate the performance of different trips and identify delays or inefficiencies.\n",
    "\n",
    "‚Ä¢ Route Optimization: Understand how delivery routes are planned and executed using open-source routing engines.\n",
    "\n",
    "‚Ä¢ Transportation Modes: Assess how different types of transport affect delivery times.\n",
    "\n",
    "‚Ä¢ Performance Benchmarking: Track delivery KPIs such as time taken, distance covered, and trip success rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† My Contribution\n",
    "## üßπ 1. Data Cleaning & Feature Engineering\n",
    "Processed and sanitized raw fields (e.g., timestamps, distances, geolocation).\n",
    "Extracted features such as:\n",
    "Average delivery time per route.\n",
    "Delay metrics per trip or region.\n",
    "Trip frequency by transport type.\n",
    "## üìä 2. Exploratory Data Analysis (EDA)\n",
    "Visualized trip durations, distances, and delays.\n",
    "Identified outliers and anomalies.\n",
    "Grouped data by city, zone, and transport type to find performance gaps.\n",
    "## üìà 3. Insights & Recommendations\n",
    "Suggested route optimization strategies based on trip repetition patterns.\n",
    "Proposed filters for early detection of delivery failures.\n",
    "Created dashboards for dynamic KPI monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "data                                0\n",
      "trip_creation_time                  0\n",
      "route_schedule_uuid                 0\n",
      "route_type                          0\n",
      "trip_uuid                           0\n",
      "source_center                       0\n",
      "source_name                       293\n",
      "destination_center                  0\n",
      "destination_name                  261\n",
      "od_start_time                       0\n",
      "od_end_time                         0\n",
      "start_scan_to_end_scan              0\n",
      "is_cutoff                           0\n",
      "cutoff_factor                       0\n",
      "cutoff_timestamp                    0\n",
      "actual_distance_to_destination      0\n",
      "actual_time                         0\n",
      "osrm_time                           0\n",
      "osrm_distance                       0\n",
      "factor                              0\n",
      "segment_actual_time                 0\n",
      "segment_osrm_time                   0\n",
      "segment_osrm_distance               0\n",
      "segment_factor                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(delivery_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "During data inspection, I found missing values in the `source_name` and `destination_name` columns.  \n",
    "To address this, I explored the possibility of imputing these values based on similarities with other columns such as:\n",
    "\n",
    "- `source_lat` and `source_long`\n",
    "- `destination_lat` and `destination_long`\n",
    "- `trip_id` or `order_time`\n",
    "\n",
    "This strategy helps retain valuable rows and ensures data completeness where patterns are identifiable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing source_name after fill: 293\n",
      "‚úÖ Missing destination_name after fill: 261\n"
     ]
    }
   ],
   "source": [
    "# Asegurar que las columnas de coordenadas existan\n",
    "for col in ['source_lat', 'source_long', 'destination_lat', 'destination_long']:\n",
    "    if col not in delivery_data.columns:\n",
    "        delivery_data[col] = np.nan\n",
    "\n",
    "# --- Rellenar source_name basado en coordenadas ---\n",
    "def fill_source_name(row):\n",
    "    if pd.isna(row['source_name']):\n",
    "        matches = delivery_data.loc[\n",
    "            (delivery_data['source_lat'] == row['source_lat']) &\n",
    "            (delivery_data['source_long'] == row['source_long']) &\n",
    "            delivery_data['source_name'].notna(), 'source_name'\n",
    "        ]\n",
    "        if not matches.empty:\n",
    "            return matches.mode().iloc[0]\n",
    "    return row['source_name']\n",
    "\n",
    "delivery_data['source_name'] = delivery_data.apply(fill_source_name, axis=1)\n",
    "\n",
    "# --- Rellenar destination_name basado en coordenadas ---\n",
    "def fill_destination_name(row):\n",
    "    if pd.isna(row['destination_name']):\n",
    "        matches = delivery_data.loc[\n",
    "            (delivery_data['destination_lat'] == row['destination_lat']) &\n",
    "            (delivery_data['destination_long'] == row['destination_long']) &\n",
    "            delivery_data['destination_name'].notna(), 'destination_name'\n",
    "        ]\n",
    "        if not matches.empty:\n",
    "            return matches.mode().iloc[0]\n",
    "    return row['destination_name']\n",
    "\n",
    "delivery_data['destination_name'] = delivery_data.apply(fill_destination_name, axis=1)\n",
    "\n",
    "# Verificaci√≥n final\n",
    "print(\"‚úÖ Missing source_name after fill:\", delivery_data['source_name'].isna().sum())\n",
    "print(\"‚úÖ Missing destination_name after fill:\", delivery_data['destination_name'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source coordinates that appear only once:\n",
      "0\n",
      "Destination coordinates that appear only once:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ver filas con source_name faltante\n",
    "missing_source = delivery_data[delivery_data['source_name'].isna()]\n",
    "# Ver si sus coordenadas existen m√°s de una vez\n",
    "source_coords_counts = delivery_data.groupby(['source_lat', 'source_long']).size().reset_index(name='count')\n",
    "missing_source = missing_source.merge(source_coords_counts, on=['source_lat', 'source_long'], how='left')\n",
    "print(\"Source coordinates that appear only once:\")\n",
    "print(missing_source[missing_source['count'] == 1].shape[0])\n",
    "\n",
    "# Ver filas con destination_name faltante\n",
    "missing_dest = delivery_data[delivery_data['destination_name'].isna()]\n",
    "# Ver si sus coordenadas existen m√°s de una vez\n",
    "dest_coords_counts = delivery_data.groupby(['destination_lat', 'destination_long']).size().reset_index(name='count')\n",
    "missing_dest = missing_dest.merge(dest_coords_counts, on=['destination_lat', 'destination_long'], how='left')\n",
    "print(\"Destination coordinates that appear only once:\")\n",
    "print(missing_dest[missing_dest['count'] == 1].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordenadas con valores v√°lidos para 'source_name':\n",
      "\n",
      "Coordenadas con valores v√°lidos para 'destination_name':\n"
     ]
    }
   ],
   "source": [
    "def check_non_null_names(missing_df, lat_col, long_col, name_col):\n",
    "    results = []\n",
    "    grouped = missing_df.groupby([lat_col, long_col])\n",
    "    for coords, group in grouped:\n",
    "        lat, long = coords\n",
    "        # Buscar si hay nombres no nulos en todas las filas con esa coordenada en el dataset original\n",
    "        valid_names = delivery_data.loc[\n",
    "            (delivery_data[lat_col] == lat) & \n",
    "            (delivery_data[long_col] == long) & \n",
    "            delivery_data[name_col].notna(),\n",
    "            name_col\n",
    "        ].unique()\n",
    "        results.append((coords, valid_names))\n",
    "    return results\n",
    "\n",
    "# Revisar source_name\n",
    "source_check = check_non_null_names(missing_source, 'source_lat', 'source_long', 'source_name')\n",
    "print(\"Coordenadas con valores v√°lidos para 'source_name':\")\n",
    "for coords, names in source_check:\n",
    "    if len(names) == 0:\n",
    "        print(f\"{coords} -> No valid names\")\n",
    "    else:\n",
    "        print(f\"{coords} -> Valid names: {names}\")\n",
    "\n",
    "# Revisar destination_name\n",
    "dest_check = check_non_null_names(missing_dest, 'destination_lat', 'destination_long', 'destination_name')\n",
    "print(\"\\nCoordenadas con valores v√°lidos para 'destination_name':\")\n",
    "for coords, names in dest_check:\n",
    "    if len(names) == 0:\n",
    "        print(f\"{coords} -> No valid names\")\n",
    "    else:\n",
    "        print(f\"{coords} -> Valid names: {names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_data['source_name'] = delivery_data['source_name'].fillna('Unknown Source')\n",
    "delivery_data['destination_name'] = delivery_data['destination_name'].fillna('Unknown Destination')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values in `source_name` and `destination_name`\n",
    "\n",
    "## Overview\n",
    "\n",
    "The dataset contains missing values in the `source_name` and `destination_name` columns. To ensure data completeness, we performed imputation based on geographic coordinates.\n",
    "\n",
    "## Steps Taken\n",
    "\n",
    "1. **Imputation Based on Coordinates**\n",
    "\n",
    "   - For rows with missing `source_name`, search other rows with the same `source_lat` and `source_long` that have a valid `source_name`.\n",
    "   - For rows with missing `destination_name`, do the same using `destination_lat` and `destination_long`.\n",
    "   - Use the most frequent (`mode`) name found to fill missing values.\n",
    "\n",
    "2. **Verification**\n",
    "\n",
    "   - After applying the imputation, count how many missing values remain in each column.\n",
    "\n",
    "3. **Analysis of Remaining Missing Values**\n",
    "\n",
    "   - Check if the coordinates corresponding to missing values are unique or appear multiple times.\n",
    "   - Confirm that no valid names exist in the dataset for these coordinates, preventing further imputation.\n",
    "\n",
    "4. **Final Fill**\n",
    "\n",
    "   - Fill remaining missing values with placeholders: `\"Unknown Source\"` and `\"Unknown Destination\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## Code Summary\n",
    "\n",
    "```python\n",
    "# Ensure coordinate columns exist\n",
    "for col in ['source_lat', 'source_long', 'destination_lat', 'destination_long']:\n",
    "    if col not in delivery_data.columns:\n",
    "        delivery_data[col] = np.nan\n",
    "\n",
    "# Functions to fill missing names based on coordinates\n",
    "def fill_source_name(row):\n",
    "    if pd.isna(row['source_name']):\n",
    "        matches = delivery_data.loc[\n",
    "            (delivery_data['source_lat'] == row['source_lat']) &\n",
    "            (delivery_data['source_long'] == row['source_long']) &\n",
    "            delivery_data['source_name'].notna(), 'source_name'\n",
    "        ]\n",
    "        if not matches.empty:\n",
    "            return matches.mode().iloc[0]\n",
    "    return row['source_name']\n",
    "\n",
    "def fill_destination_name(row):\n",
    "    if pd.isna(row['destination_name']):\n",
    "        matches = delivery_data.loc[\n",
    "            (delivery_data['destination_lat'] == row['destination_lat']) &\n",
    "            (delivery_data['destination_long'] == row['destination_long']) &\n",
    "            delivery_data['destination_name'].notna(), 'destination_name'\n",
    "        ]\n",
    "        if not matches.empty:\n",
    "            return matches.mode().iloc[0]\n",
    "    return row['destination_name']\n",
    "\n",
    "# Apply the functions\n",
    "delivery_data['source_name'] = delivery_data.apply(fill_source_name, axis=1)\n",
    "delivery_data['destination_name'] = delivery_data.apply(fill_destination_name, axis=1)\n",
    "\n",
    "# Check remaining missing values\n",
    "print(\"Missing source_name after fill:\", delivery_data['source_name'].isna().sum())\n",
    "print(\"Missing destination_name after fill:\", delivery_data['destination_name'].isna().sum())\n",
    "\n",
    "# Fill remaining missing values with placeholders\n",
    "delivery_data['source_name'] = delivery_data['source_name'].fillna('Unknown Source')\n",
    "delivery_data['destination_name'] = delivery_data['destination_name'].fillna('Unknown Destination')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_data['od_end_time'] = pd.to_datetime(delivery_data['od_end_time'], errors='coerce')\n",
    "delivery_data['od_start_time'] = pd.to_datetime(delivery_data['od_start_time'], errors='coerce')\n",
    "delivery_data['od_duration'] = (delivery_data['od_end_time'] - delivery_data['od_start_time']).dt.total_seconds() / 3600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
